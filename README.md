# Customer Support AI Assistant

## ğŸ” Overview
This project is a **Retrieval-Augmented Generation (RAG)** based AI assistant designed to answer customer support queries. It retrieves the most relevant historical Q&A data and generates contextual, human-like responses using the **`mistralai/mistral-7b-instruct`** model via **OpenRouter.ai** API.

The app is now **fully deployed** with optimized performance and dual interfaces â€” powered by **FastAPI** and a more interactive **Gradio** UI for quick testing.

---

## âœ… Submission Checklist
- [x] Clean, modular GitHub repository âœ…  
- [x] Fully deployed model integration with OpenRouter âœ…  
- [x] FastAPI and Gradio interfaces âœ…  
- [x] Optimized codebase for performance âœ…  
- [x] README and PPT with approach, RAG details, and explainability âœ…  

---

## ğŸ› ï¸ Tech Stack
- Python  
- FastAPI  
- Gradio  
- FAISS (Facebook AI Similarity Search)  
- Hugging Face SentenceTransformers (`all-MiniLM-L6-v2`)  
- OpenRouter API (`mistralai/mistral-7b-instruct`)  

---

## ğŸ§  Approach Taken

1. **Data Loading & Cleaning:**
   - Loaded customer support Q&A dataset from Hugging Face: `MohammadOthman/mo-customer-support-tweets-945k`
   - Removed nulls and duplicates, saved as `clean_data.csv`.

2. **Embedding & Indexing:**
   - Used `all-MiniLM-L6-v2` for semantic embedding.
   - Built FAISS index for fast vector similarity search.

3. **RAG Pipeline:**
   - **Retrieval:** Top 3 most semantically similar Q&As are selected.
   - **Augmentation:** Prompt is formed using retrieved context and the user query.
   - **Generation:** Prompt sent to `mistralai/mistral-7b-instruct` via OpenRouter API to generate a helpful, context-aware answer.

4. **Serving the App:**
   - **FastAPI** backend with `/generate` endpoint.
   - **Gradio** front-end for real-time interaction (preferred for usability).

---

## ğŸ”„ RAG Implementation
**Retrieval**  
- Embeds and indexes Q&A pairs using `all-MiniLM-L6-v2` + FAISS  
- Uses L2 similarity to retrieve relevant examples

**Augmentation**  
- Combines top 3 retrieved Q&As with the user query to build the context-rich prompt

**Generation**  
- Prompt passed to `mistralai/mistral-7b-instruct` via OpenRouter  
- Output is cleaned and post-processed for delivery

---

## ğŸ“¢ Explainability Techniques
- Matching Q&As and similarity scores are logged for traceability.
- Debugging and transparency supported with optional logs.
- *(Planned)* LIME/SHAP integration for deeper model understanding.

---

## ğŸ“¦ Directory Structure
```
customer-support-ai/
â”œâ”€â”€ app.py                            # FastAPI app entrypoint
â”œâ”€â”€ pipeline.py                       # RAG pipeline (retriever + generator)
â”œâ”€â”€ requirements.txt                  # Dependencies
â”œâ”€â”€ README.md                         # Project overview & how to run
â”œâ”€â”€ .gitignore                        # Ignore unwanted files (e.g., __pycache__)
â”‚
â”œâ”€â”€ rag/                              # Core logic of RAG
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ embedder.py                   # SentenceTransformer embedder
â”‚   â”œâ”€â”€ vector_store.py               # FAISS vector DB logic
â”‚   â”œâ”€â”€ retriever.py                  # Retrieval logic
â”‚   â”œâ”€â”€ generator.py                  # LLM-based response generator
â”‚
â”œâ”€â”€ test/                             # Test scripts for each module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_embedder.py              # (optional, can test embeddings)
â”‚   â”œâ”€â”€ test_vector_store.py
â”‚   â”œâ”€â”€ test_retriever.py
â”‚   â”œâ”€â”€ test_generator.py
â”‚   â”œâ”€â”€ test_pipeline.py
â”‚
â”œâ”€â”€ dataset/                          # Dataset preprocessing & raw/clean files
â”‚   â”œâ”€â”€ dataset_preprocessor.py
â”‚   â”œâ”€â”€ raw/                          # (optional) raw downloaded files
â”‚   â””â”€â”€ storage/                      # Cleaned CSV, FAISS index, mapping.pkl
â”‚       â”œâ”€â”€ clean_data.csv
â”‚       â”œâ”€â”€ faiss_index.index
â”‚       â”œâ”€â”€ mapping.pkl
â”‚
â”œâ”€â”€ logs/                             # Logs for interaction history
â”‚   â””â”€â”€ conversations.csv


```

---

## ğŸš€ How to Run Locally
```bash
# Step 1: Install dependencies
pip install -r requirements.txt

# Step 2: Run FastAPI server
uvicorn app.main:app --reload
```

---

## ğŸš€ How to Run Locally
```bash
# Step 1: Install dependencies
pip install -r requirements.txt

# Step 2: Run FastAPI server
uvicorn app:app --reload

# (Optional) Run Gradio UI
python gradio_ui.py

---

## ğŸš€ Notes on security

API keys (OpenRouter) are stored in .env and never exposed.

python-dotenv handles secure loading of environment variables.

---

## ğŸ”— Live Demo

https://costumer-support-ai-asistant-1.onrender.com/docs

----

## ğŸ¤ Credits
Built by Aadil Maqbool for the Customer Support AI Assistant Challenge.

